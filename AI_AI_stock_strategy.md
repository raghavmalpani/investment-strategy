# AI-Focused Equity Strategy

## Investment Thesis Snapshot
- Generative AI adoption is accelerating across both closed-domain (medicine, finance, compliance) and open-domain workflows, creating durable demand for model providers and infrastructure.
- Constrained prompting and tool integration allow LLMs to extend human reasoning in open systems, unlocking premium workflows for vertical software.
- Run-time code synthesis ("JSON-to-runtime compilation") positions AI platforms as execution layers, driving platform lock-in and higher switching costs.
- Hyper-personalization will expand across consumer and enterprise touchpoints (marketing, commerce, productivity) as models become context-aware and subtle recommendation engines.
- Unit economics of AI (cost/latency/hallucinations) continue to improve as models scale and specialized hardware matures, broadening customer TAM.
- Software engineering leverage is compounding; productivity gains shift value toward companies that harness AI for product velocity.

## Market Segmentation
- **AI Infrastructure**
  - *Compute Stack (Chips & Cloud)*: NVIDIA, AMD, TSMC, Google TPU silicon, AWS, Microsoft Azure, Google Cloud, Meta, Oracle Cloud — focus on wafer supply, GPU/ASIC availability, AI-specific capex, and differentiated inference/training services.
  - *Critical Enablers*: Networking (Arista, Broadcom), memory (Samsung, SK Hynix, Micron), advanced packaging (ASE, Amkor), power/cooling (Vertiv, Eaton), colo REITs (Equinix, Digital Realty) — track backlog, pricing, and infrastructure bottlenecks that govern AI throughput.
  - *Model & Talent Overlay*: OpenAI, Anthropic, Google DeepMind, Cohere — treat frontier model capability as a moat overlay topping other holdings rather than a standalone sleeve; monitor release cadence and strategic partnerships that influence both infra and product names.
- **AI Distribution & Product**
  - *Endpoint Gatekeepers*: Apple, Alphabet (Android), automotive OEMs (Tesla, GM), industrial platforms (Siemens, Schneider) — watch for native agent/voice integration, OS-level APIs, and regulatory scrutiny around ecosystem control.
  - *Vertical AI Leaders*: Break out by use-case adoption curves
    - Productivity & DevOps (Microsoft Copilot, Atlassian, ServiceNow)
    - Commerce & Ads (Amazon, Shopify, MercadoLibre, advertising platforms)
    - Industrial & Logistics Automation (John Deere, ABB, autonomous warehouse providers)
    - Healthcare & Regulated Services (Intuitive Surgical, Teladoc, diagnostics AI)
    - Consumer Social & Media (Snap, Reddit, Netflix) when AI enhances personalization and engagement.
    Evaluate each for measurable AI-derived revenue, data rights, and compliance posture before scaling exposure.

## Risk/Reward Positioning
- **Compute stack**: Demand visibility is strong but cyclical; monitor export controls, node transitions, and hyperscaler ROI to avoid overpaying for peak earnings.
- **Critical enablers**: Supply bottlenecks create asymmetric upside, yet customer concentration and pricing power can reverse quickly when capacity normalizes — maintain diversification across sub-components.
- **Endpoint gatekeepers**: Ecosystem control provides resilience, but antitrust and platform policy shifts can compress economics; size positions with regulatory headlines in mind.
- **Vertical leaders**: Outcome dispersion is widest — require proof of AI monetization (attach rates, AI ARR growth) and regulatory clearance (especially in healthcare/industrial) before increasing allocation.
- **Overlay discipline**: Use model/talent partnerships to upgrade moat assessments within other sleeves rather than allocating capital directly to private/illiquid labs.

## Data Collection Playbook
- **Compute Stack (Chips & Cloud)**
  - Core metrics: data center GPU/ASIC revenue run-rate, wafer starts by node, hyperscaler AI capex, GPU fleet utilization, inference vs training mix, gross margin impact from AI workloads.
  - Leading indicators: long-term supply agreements, export control disclosures, new instance launches, price-per-token trends, data center build-out pace.
  - Sources: 10-Q/K filings, earnings transcripts, industry trackers (TrendForce, Canalys), developer conference releases.
- **Critical Enablers**
  - Core metrics: networking/backplane revenue growth, AI-driven backlog, memory ASPs, advanced packaging capacity utilization, colocation occupancy and FFO growth.
  - Leading indicators: lead-time commentary, hyperscaler order visibility, power/cooling retrofit announcements, supply-chain inventories.
  - Sources: supplier updates, manufacturing import/export data, hyperscaler procurement disclosures, industry newsletters.
- **Endpoint Gatekeepers**
  - Core metrics: active device/install base, shipments with AI-capable silicon, services revenue tied to agents/voice, developer monetization from new AI APIs, connected vehicle fleet size.
  - Leading indicators: OS policy changes, default agent announcements, regulatory filings, strategic partnerships with model providers or auto suppliers.
  - Sources: product launches, teardown reports, regulatory dockets, developer documentation, mobility data services.
- **Vertical AI Leaders**
  - Productivity & DevOps: AI ARR mix, seat expansions, developer productivity case studies, attach rates for coding/office copilots.
  - Commerce & Ads: conversion uplift from AI recommendations, ad-targeting ROAS metrics, fulfillment automation KPIs, AI-driven take-rate changes.
  - Industrial & Logistics: autonomous hour utilization, safety incidents, maintenance cost reductions, regulatory certifications for autonomous operations.
  - Healthcare & Regulated: clinical trial outcomes, FDA/CE approvals, reimbursement codes, malpractice or compliance disclosures.
  - Consumer Social & Media: engagement lift, personalization metrics, content moderation costs, policy changes around user data consent.
  - Sources: earnings materials, customer case studies, alternative data providers, regulatory databases, industry-specific research firms.

## Capital Deployment Framework (High-Risk Sleeve)
- **Risk budget**: Treat this portfolio as a growth sleeve distinct from core ETF holdings; tolerate >30% drawdowns by sizing positions to thesis confidence rather than volatility minimization.
- **Portfolio allocation**: 40% platform (compute stack + critical enablers), 60% product (endpoint gatekeepers + vertical AI leaders).
- **Platform sleeve (40%)**:
  - 25–30% compute stack bellwethers (chips, foundry, cloud compute)
  - 10–15% critical enablers (networking, memory, power, packaging)
  - Maintain this anchor to keep portfolio tethered to AI infrastructure demand even if product bets take longer to play out.
- **Product sleeve (60% - TBD)**:
  - Breakdown pending additional research on product stocks (endpoint gatekeepers, vertical AI leaders, dry powder allocation).
  - Will determine specific allocations after scoring product segment candidates.
- **Options/LEAPS allocation**: 5–10% of total portfolio, never exceeding 10%. Use for:
  - High-conviction thesis plays with defined catalysts (earnings, product launches, regulatory approvals)
  - Asymmetric upside on smaller positions without diluting equity exposure
  - Event-driven opportunities when spot equity position is capped by risk limits
- **Position sizing**: Cap initial single-name weights at 8–10% unless the scoring average is ≥4.5 with no trigger flags; pyramid into winners as KPIs beat thresholds (AI ARR growth >30% YoY, utilization >85%).
- **Rebalance cadence**: Monthly light-touch checks for trigger flags; full rebalance post-earnings. Harvest gains when a position exceeds 1.5× its target weight or when score momentum turns negative for two consecutive reviews.
- **Risk controls**: Use stop-loss alerts tied to thesis breakpoints (regulatory denial, capex reversals) rather than price-only triggers; be prepared to rotate proceeds within the same segment to maintain desired exposure.

## Watchlist Seeds
- See `AI_watchlist_seeds.md` for the current ticker lineup and collection notes.
